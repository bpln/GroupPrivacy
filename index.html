<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<title>Free xhtml template - minimalistic-design.com</title>	
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>

	<div id="page">

		<div id="header">
		<h1><a href="#">GroupPriv</a></h1>
			<h2> Group Privacy-aware Disclosure of Association Graph Data</h2>
		</div>

		<div id="wrapper">

			<div id="content">

				<h2>Overview</h2>
				<div id="index_image">
					<img width="200px" src="figures/index_figure_200.jpg" alt="index_image" />
				</div>
				<b><big>GroupPriv</big></b> is a privacy-aware data disclosure scheme that considers group privacy 
				requirements of individuals in bipartite association graph datasets (e.g., graphs that represent 
				associations between entities such as customers and products bought from a pharmacy store). 
				
				<br /><br />
				The key features include the new notion of &epsilon;<sub>g</sub>-Group Differential Privacy that
				protects sensitive information of groups of individuals at various defined group protection
				levels, enabling data users to obtain the level of information entitled to them.</li> 
				It includes a suite of differentially private mechanisms that protect group privacy in bipartite 
			        association graphs at different group privacy levels based on specialization hierarchies.</li>
					
				</ul> 
				<br /><br />
				
				<h2>Motivation</h2> 
				<p>
				Conventional differential privacy mechanisms are designed to protect the privacy of individual's information.
                In certain situations, even aggregate (statistical) information about individuals may not be safe for disclosure 
					as the aggregate information itself can be sensitive and may need protection. 

                In general, sensitive information may arise either as:

                <ul>
                	<li>an individual sensitive value indicating an individualâ€™s private information (e.g., did 
				buyer â€˜Bobâ€™ purchase the drug â€˜insulinâ€™?) in a dataset</li>
                	<li>a statistical value representing some sensitive statistics about a group/sub-group of
				individuals (e.g., the total number of â€˜Psychiatricâ€™ drugs purchased by buyers in a given
				neighborhood represented by a zipcode).</li>
                </ul>
				</p>

				<br /><br />

				<h2>Group Differential Privacy</h2> 
				<div>Group Differential Privacy extends the conventional notion of differential privacy model to
					protect privacy of groups of individuals at various group granularity levels. 
					We focus on the scenarios where one needs to protect group-level privacy in 
					addition to individual privacy, where a group consists of a set of individuals. 
					We define the proposed notion of g - group differential privacy by considering
					adjacent data sets from a group privacy perspective.</div>
				<div id="group">
					<img width="450px" src="figures/group.jpg" alt="group" />
				</div>
				
				<br /><br />

				<h2>Mechanisms</h2> 
				<p>
				The approach consists of two parts:
					<ul>
						<li>The first part of the proposed approach, namely <i>DiffPar</i> hierarchically 
							partitions and groups the nodes and edges of the given association graph
							into different levels of granularity of disclosure in terms of group size
							considering the sensitivity of the formed groups</li>
						<li>The second component of the algorithm, namely <i>DiffAggre</i> performs a 
							bottom-up aggregation and noise injection to guarantee g-group differential
							privacy in the published dataset</li>
					</ul>
				</p>
				<div id="mechanism">
					<img width="450px" src="figures/mechanism.jpg" alt="mechanism" />
				</div>
				
				<br /><br />

				<h2 id="publications">Publications</h2> 
				<ul>
					<li>Balaji Palanisamy, Chao Li and Prashant Krishnamurthy, "Group Differential Privacy-preserving Disclosure of Multi-level Association Graphs", Proc. of 37th IEEE International Conference on Distributed Computing Systems (<b>ICDCS 2017</b>), Atlanta, USA. [poster] [<a href="http://www.sis.pitt.edu/bpalan/papers/GroupDP-ICDCS2017.pdf">PDF</a>]</li>
					<li>Balaji Palanisamy, Chao Li and Prashant Krishnamurthy, "Group Privacy-aware Disclosure of Association Graph Data", in submission.</li>
				</ul>

				<br /><br />

				<h2 id="slides">Slides</h2> 
				<iframe src='https://onedrive.live.com/embed?cid=A737BC6B61F2678C&resid=A737BC6B61F2678C%21132497&authkey=AJmOgU-L9eELIg4&em=2&wdAr=1.7777777777777777' width='490px' height='300px' frameborder='0'>This is an embedded <a target='_blank' href='https://office.com'>Microsoft Office</a> presentation, powered by <a target='_blank' href='https://office.com/webapps'>Office Online</a>.</iframe>
				

			</div>

			<div id="sidebar"> 

				<h2>Menu Navigation</h2>

				<ul>
					<li><a href="index.html">Overview</a></li> 
					<li><a href="downloads.html">Downloads</a></li> 
					<li><a href="people.html">People</a></li> 
					<li><a href="index.html#publications">Publications</a></li>
				</ul>

				<h2>Useful Resources</h2>

				<ul>
					<li><a href="http://jmcauley.ucsd.edu/data/amazon/">Amazon product review dataset</a></li>  
					<li><a href="https://labrosa.ee.columbia.edu/millionsong/lastfm">Last.fm songs dataset</a></li>  
					<li><a href="https://grouplens.org/datasets/movielens/100k/">MovieLens 100k dataset</a></li>  
				</ul>

			</div>

			<div style="clear: both;"> </div>

		</div>

		<div id="footer">
			<p>
				
			</p>
		</div>

	</div>


</body>

</html>
